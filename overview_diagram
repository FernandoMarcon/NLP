NLTK setup

read text data - load_data(filename)
    import pandas as pd
    messages = pd.read_csv('somedirectory/spam.csv', encoding='latin-1')
    messages.head()

clean text data - clean_data(text)
  - remove punctuation - remove_punctuation(text)
        def remove_punct(text):
        text = "".join([char for char in text if char not in string.punctuation])
        return text
  - Tokenization - tokenize(text)
  - Remove Stopwords - remove_stopwords(tokenized_text)
  - Stemming - stemm_text(text)
  - Lemmatizing - lemma_text(text)

vectorize
  - Count vectorization
  - N-grams
  - TF-IDF - TfidVectorizer()
        from  sklearn.feature_extraction.text import TfidfVectorizer
        tfidf_vecf = TfidfVectorizer(analyzer=clean_text)
        tfidf_vect.fit_transform(messages['text'])

Feature Engineering
  - Feature Creation
    - Length of text field
    - Percentage of characters that are punctuation in the text
    - Percentage of characters that are capitalized
  - Transformations
    - Power transformations
      - Box-Cox Power Transformations
  - Standardizing data

Model Building and Evaluation
  1. Split the data into training and test set. train_test_split(X_features, label, test_size = .20)

  2. Train vectorizers on training set and use that to transform test set.
      rf = RandomForestClassifier()
      rf_model = rf.fit(X_train, y_train)

  3. Fit best random forest model and best gradient boosting model on training set and predict on test set.
    Build model
      - Supervised Learning
        + Random Forest (class: Ensemble Models)
        + Gradient Boosting (class: Ensemble Models)
        + Recurrent Neural Networks (class: )

      - Unsupervised Learning

  4. Thoroughly evaluate results of these two models to select best model
    - Evaluation Metrics - sklearn.metrics
      - Accuracy - sum(y_pred == y_test) / len(y_test)
      - Precision - precision_score
      - Recall  - recall_score

    - Holdout Test Set
      - _K_-Fold Cross-Validation
      - Grid-search
      - Cross-validation




word2vec
doc2vec
